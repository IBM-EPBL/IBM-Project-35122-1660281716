{"cells": [{"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 131, "outputs": [{"output_type": "execute_result", "execution_count": 131, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "!pip install keras\n!pip install tensorflow\n", "execution_count": 132, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: keras in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.7.0)\nRequirement already satisfied: tensorflow in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.7.2)\nRequirement already satisfied: gast<0.5.0,>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: wheel<1.0,>=0.32.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.23.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.42.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (4.1.1)\nRequirement already satisfied: keras<2.8,>=2.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (2.7.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.12.0)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.20.3)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (3.2.1)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (3.19.1)\nRequirement already satisfied: tensorflow-estimator<2.8,~=2.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (2.7.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: tensorboard~=2.7 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (2.7.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (58.0.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (3.3.3)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (0.6.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (2.0.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (2.26.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (1.6.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (1.23.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (0.4.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.7->tensorflow) (0.2.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.7->tensorflow) (4.2.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.7->tensorflow) (4.7.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.7->tensorflow) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.7->tensorflow) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.7->tensorflow) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.7->tensorflow) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.7->tensorflow) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.7->tensorflow) (3.3)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.7->tensorflow) (3.2.1)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator (rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\ntest_datagen = ImageDataGenerator (rescale = 1./255)", "execution_count": 133, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='IyC4hWKlZ9teRhnvGIAhEEVailtnqXbdhHICDn8DE5OZ',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'imageclassification-donotdelete-pr-j1138lt7m39req'\nobject_key = 'archive.zip'\n\nstreaming_body_7 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 134, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "GmTRUrzJ141n", "outputId": "591f94d1-2847-4761-97a8-7ad6abbb6937"}, "cell_type": "code", "source": "import io\nfrom io import BytesIO\nimport zipfile\nunzip = zipfile.ZipFile(BytesIO(streaming_body_7.read()), 'r')\nfile_paths = unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 135, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "b7K1Rhd5HeFJ", "outputId": "ca612fd0-35f0-499c-9fee-f7e045e95a1a"}, "cell_type": "code", "source": "pwd", "execution_count": 136, "outputs": [{"output_type": "execute_result", "execution_count": 136, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "import os\nfilenames=os.listdir('/home/wsuser/work')", "execution_count": 137, "outputs": []}, {"metadata": {"id": "I2UJVZw8Ijw5"}, "cell_type": "markdown", "source": "**Image Preprocessing**\n\n"}, {"metadata": {"id": "bZT5qR_wjcOe"}, "cell_type": "code", "source": "# import keras library\nimport keras\n#import ImageDataGenerator from keras.preprocessing.image\nfrom keras.preprocessing.image import ImageDataGenerator ", "execution_count": 138, "outputs": []}, {"metadata": {"id": "fKBMB76VIxRN"}, "cell_type": "code", "source": "import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory", "execution_count": 139, "outputs": []}, {"metadata": {"id": "ybiq2pzyI7AU"}, "cell_type": "code", "source": "\ntrain_datagen = ImageDataGenerator(\n                                   rotation_range=180,\n                                   brightness_range=None,\n                                   shear_range=0.4,\n                                   zoom_range=0.3,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   rescale=1./255,)", "execution_count": 140, "outputs": []}, {"metadata": {"id": "9TxKpSpuKt3-"}, "cell_type": "code", "source": "\ntest_datagen = ImageDataGenerator(rescale=1./255)", "execution_count": 141, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "z7lHSWIfLjkp", "outputId": "3f8dcece-6617-4eea-8282-56673c4b5437"}, "cell_type": "code", "source": "xtrain = train_datagen.flow_from_directory('//home/wsuser/work/Dataset/Dataset/train_set',\n                                           target_size=(64,64),\n                                           class_mode='binary',\n                                           batch_size=100)", "execution_count": 142, "outputs": [{"output_type": "stream", "text": "Found 436 images belonging to 2 classes.\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "DLFy3Po3MBLF", "outputId": "4fedddac-dda1-48ac-ce03-af30c861a593"}, "cell_type": "code", "source": "xtest = train_datagen.flow_from_directory('//home/wsuser/work/Dataset/Dataset/test_set',\n                                           target_size=(64,64),\n                                           class_mode='binary',\n                                           batch_size=100)", "execution_count": 143, "outputs": [{"output_type": "stream", "text": "Found 121 images belonging to 2 classes.\n", "name": "stdout"}]}, {"metadata": {"id": "_86n1NiEA6fD"}, "cell_type": "markdown", "source": "**Model Building**"}, {"metadata": {"id": "JfEUueUJBBE7"}, "cell_type": "markdown", "source": "1. Import the Model Builing Libraries"}, {"metadata": {"id": "kVKDcezp4QaL"}, "cell_type": "code", "source": "import warnings\nwarnings.filterwarnings('ignore')\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Convolution2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten", "execution_count": 144, "outputs": []}, {"metadata": {"id": "EaIhJya8B17X"}, "cell_type": "markdown", "source": "2. Initialize the Model"}, {"metadata": {"id": "kDoV7DT2BeRD"}, "cell_type": "code", "source": "model = Sequential()", "execution_count": 145, "outputs": []}, {"metadata": {"id": "h_ABk5KZCEsS"}, "cell_type": "markdown", "source": "3. Adding CNN Layers"}, {"metadata": {"id": "doLfETtTCAgD"}, "cell_type": "code", "source": "#Convolution Layer\nmodel.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))", "execution_count": 146, "outputs": []}, {"metadata": {"id": "hndEc-WHCKMS"}, "cell_type": "code", "source": "#MaxPooling Layer\nmodel.add(MaxPooling2D(pool_size=(2, 2)))", "execution_count": 147, "outputs": []}, {"metadata": {"id": "3Pqc-JeWCVxl"}, "cell_type": "code", "source": "#Flatten Layer\nmodel.add(Flatten())", "execution_count": 148, "outputs": []}, {"metadata": {"id": "e52S58PGCuiZ"}, "cell_type": "markdown", "source": "4. Adding Dense Layer"}, {"metadata": {"id": "XAh5JiOLCaR4"}, "cell_type": "code", "source": "#Hidden Layer\nmodel.add(Dense(350,activation='relu')) # Hidden layer 1\nmodel.add(Dense(200,activation='relu')) # Hidden layer 2", "execution_count": 149, "outputs": []}, {"metadata": {"id": "dcb4jLSqCg5C"}, "cell_type": "code", "source": "#Output Layer\nmodel.add(Dense(1,activation='softmax'))", "execution_count": 150, "outputs": []}, {"metadata": {"id": "RFTLHyhICw_m"}, "cell_type": "markdown", "source": "5. Configuring The Learning Process"}, {"metadata": {"id": "I95qfZU7ConD"}, "cell_type": "code", "source": "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])", "execution_count": 151, "outputs": []}, {"metadata": {"id": "_qd6UCQ9C-l0"}, "cell_type": "markdown", "source": "6. Training the Model"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "noP4oQGzC830", "outputId": "096f742b-7153-40ec-a458-d645c35084c3"}, "cell_type": "code", "source": "model.fit_generator(xtrain,\n                    steps_per_epoch=len(xtrain),\n                    epochs=10,\n                    validation_data=xtest,\n                    validation_steps=len(xtest))", "execution_count": 152, "outputs": [{"output_type": "stream", "text": "Epoch 1/10\n5/5 [==============================] - 20s 4s/step - loss: 1.3503 - accuracy: 0.3555 - val_loss: 0.5218 - val_accuracy: 0.4050\nEpoch 2/10\n5/5 [==============================] - 16s 3s/step - loss: 0.6692 - accuracy: 0.3555 - val_loss: 0.4354 - val_accuracy: 0.4050\nEpoch 3/10\n5/5 [==============================] - 16s 3s/step - loss: 0.4893 - accuracy: 0.3555 - val_loss: 0.3198 - val_accuracy: 0.4050\nEpoch 4/10\n5/5 [==============================] - 16s 3s/step - loss: 0.4236 - accuracy: 0.3555 - val_loss: 0.2719 - val_accuracy: 0.4050\nEpoch 5/10\n5/5 [==============================] - 16s 3s/step - loss: 0.2920 - accuracy: 0.3555 - val_loss: 0.1523 - val_accuracy: 0.4050\nEpoch 6/10\n5/5 [==============================] - 16s 3s/step - loss: 0.2623 - accuracy: 0.3555 - val_loss: 0.1195 - val_accuracy: 0.4050\nEpoch 7/10\n5/5 [==============================] - 16s 3s/step - loss: 0.2282 - accuracy: 0.3555 - val_loss: 0.1379 - val_accuracy: 0.4050\nEpoch 8/10\n5/5 [==============================] - 16s 4s/step - loss: 0.2047 - accuracy: 0.3555 - val_loss: 0.0951 - val_accuracy: 0.4050\nEpoch 9/10\n5/5 [==============================] - 16s 4s/step - loss: 0.1842 - accuracy: 0.3555 - val_loss: 0.1037 - val_accuracy: 0.4050\nEpoch 10/10\n5/5 [==============================] - 17s 3s/step - loss: 0.1709 - accuracy: 0.3555 - val_loss: 0.0917 - val_accuracy: 0.4050\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 152, "data": {"text/plain": "<keras.callbacks.History at 0x7fad24ce8490>"}, "metadata": {}}]}, {"metadata": {"id": "mW4gF91DG8RC"}, "cell_type": "markdown", "source": "7. Saving the Model"}, {"metadata": {"id": "qtMDnl3VF0QG"}, "cell_type": "code", "source": "model.save('Forest_fire.h5')", "execution_count": 153, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf image-classification-model_new.tgz Forest_fire.h5\n", "execution_count": 154, "outputs": [{"output_type": "stream", "text": "Forest_fire.h5\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ls -1", "execution_count": 155, "outputs": [{"output_type": "stream", "text": "\u001b[0m\u001b[01;34mDataset\u001b[0m/\r\nforest1.h5\r\nForest_fire.h5\r\nimage-classification-model_new.tgz\r\nmy_model1.tar.gz\r\nmy_model.tar.gz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson-machine-learning-client --upgrade", "execution_count": 156, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: watson-machine-learning-client in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.391)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\nRequirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nwml_credentials = {\n\"url\": \"https://us-south.ml.cloud.ibm.com\",\n\"apikey\":\"m4-xXEK8_bmzcb-5YEf11ai2gFIAL-L84TI6LRNeo3K1\"\n}\nclient= APIClient (wml_credentials)", "execution_count": 157, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client= APIClient (wml_credentials)", "execution_count": 158, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def guid_from_space_name(client, space_name):\n    space = client.spaces.get_details()\n    return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['id'])", "execution_count": 159, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid = guid_from_space_name (client, 'image-classification')\nprint(\"Space UID = \"+ space_uid)", "execution_count": 160, "outputs": [{"output_type": "stream", "text": "Space UID = 02cde4c6-ce63-4709-90ee-abbd57c0cda0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space (space_uid)", "execution_count": 161, "outputs": [{"output_type": "execute_result", "execution_count": 161, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list()", "execution_count": 162, "outputs": [{"output_type": "stream", "text": "-----------------------------  ------------------------------------  ----\nNAME                           ASSET_ID                              TYPE\ndefault_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\nkernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\npytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\npytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\nai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nautoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\nruntime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\nscikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\nkernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\npytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\ntensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\nspark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\ntensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\nruntime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\ndo_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\nkernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\npytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\nautoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\nxgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\npytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\ndefault_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\nautoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\nautoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\npmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\nspark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nautoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\npytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n-----------------------------  ------------------------------------  ----\nNote: Only first 50 records were displayed. To display more use 'limit' parameter.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow_rt22.1-py3.9\")\nsoftware_spec_uid", "execution_count": 163, "outputs": [{"output_type": "execute_result", "execution_count": 163, "data": {"text/plain": "'acd9c798-6974-5d2f-a657-ce06e986df4d'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_details = client.repository.store_model (model='image-classification-model_new.tgz',meta_props={\n    client.repository. ModelMetaNames.NAME: \"CNN\",\n    client.repository.ModelMetaNames.TYPE: \"tensorflow_2.7\",\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n    })\nmodel_id = client.repository.get_model_uid (model_details)", "execution_count": 164, "outputs": [{"output_type": "stream", "text": "This method is deprecated, please use get_model_id()\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model_id", "execution_count": 165, "outputs": [{"output_type": "execute_result", "execution_count": 165, "data": {"text/plain": "'aab649db-b904-46c0-a679-c41d60fe8faf'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download (model_id, 'my_model2.tar.gz')", "execution_count": 167, "outputs": [{"output_type": "stream", "text": "Successfully saved model content to file: 'my_model2.tar.gz'\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 167, "data": {"text/plain": "'/home/wsuser/work/my_model2.tar.gz'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "from keras.models import load_model\nfrom keras.preprocessing import image", "execution_count": 168, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model = load_model(\"Forest_fire.h5\")", "execution_count": 169, "outputs": []}, {"metadata": {"id": "M-sGToJUHOWG"}, "cell_type": "code", "source": "from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image", "execution_count": 170, "outputs": []}, {"metadata": {"id": "X2Wq2lu4IA-o"}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='m4-xXEK8_bmzcb-5YEf11ai2gFIAL-L84TI6LRNeo3K1',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'imageclassification-donotdelete-pr-j1138lt7m39req'\nobject_key = 'Fire-Forest.jpg'\n\nstreaming_body_8 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n\n\n", "execution_count": 171, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "streaming_body_8 ", "execution_count": 172, "outputs": [{"output_type": "execute_result", "execution_count": 172, "data": {"text/plain": "<ibm_botocore.response.StreamingBody at 0x7fad71e88f40>"}, "metadata": {}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 81}, "id": "mDOmQspyIPz7", "outputId": "bba4a231-5eae-4896-eaaa-a5570e47f35b"}, "cell_type": "code", "source": "!pip install load", "execution_count": 173, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: load in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2020.12.3)\r\n", "name": "stdout"}]}, {"metadata": {"id": "0EEgbXKUJsdx"}, "cell_type": "code", "source": "img = image.load_img(streaming_body_8,target_size = (128,128))", "execution_count": 174, "outputs": [{"output_type": "error", "ename": "TypeError", "evalue": "expected str, bytes or os.PathLike object, not StreamingBody", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_164/2189728808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreaming_body_8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    311\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[0;32m--> 313\u001b[0;31m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[1;32m    314\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not StreamingBody"]}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "TqPPPz14IfR1", "outputId": "688b51c2-81d4-4ceb-91ae-5f61120cad52"}, "cell_type": "code", "source": "pred=model.predict(x)", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "xPEJIgn9KJY1", "outputId": "a60ea006-1e37-4517-ee93-44bee6cd12f7"}, "cell_type": "code", "source": "print (pred)", "execution_count": null, "outputs": []}, {"metadata": {"id": "CurxveAj1j2X"}, "cell_type": "markdown", "source": "Video Analysis\n\nOpenCV For Video Processing\n\n1: Capture Video from Camera"}, {"metadata": {"id": "OylMddWC17KR"}, "cell_type": "code", "source": "import cv2\nimport numpy as np\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "zu-gfDB-2Gdr", "outputId": "ad1c6887-4c2a-4282-96af-794ea9251edc", "colab": {"base_uri": "https://localhost:8080/"}}, "cell_type": "code", "source": "pip install twilio", "execution_count": null, "outputs": []}, {"metadata": {"id": "82xnRUgt2XOj"}, "cell_type": "code", "source": "from twilio.rest import Client", "execution_count": null, "outputs": []}, {"metadata": {"id": "9Di-N4sQ2bl7", "outputId": "353fb787-a494-4870-edd9-dcdc800625ef", "colab": {"base_uri": "https://localhost:8080/"}}, "cell_type": "code", "source": "pip install playsound", "execution_count": null, "outputs": []}, {"metadata": {"id": "wJbe9Hr42kWa", "outputId": "6bf85bf2-72cc-4a54-bffa-e3b2ffd100ad", "colab": {"base_uri": "https://localhost:8080/"}}, "cell_type": "code", "source": "pip install pygobject", "execution_count": null, "outputs": []}, {"metadata": {"id": "fcZHugWY2r3z", "outputId": "3b091075-d658-4323-d674-f6e17e8da70c", "colab": {"base_uri": "https://localhost:8080/"}}, "cell_type": "code", "source": "from playsound import playsound", "execution_count": null, "outputs": []}, {"metadata": {"id": "_SJp32p63Xj0"}, "cell_type": "markdown", "source": "3: Loading our saved model file using load_model from Keras library"}, {"metadata": {"id": "BV9v2VOh3YhX"}, "cell_type": "code", "source": "model = load_model(r'forest1.h5')", "execution_count": null, "outputs": []}, {"metadata": {"id": "uDUOXLhM3rsC"}, "cell_type": "code", "source": "video = cv2.VideoCapture(0)", "execution_count": null, "outputs": []}, {"metadata": {"id": "CAG37usg3xeC"}, "cell_type": "code", "source": "name = ['forest', 'with fire']", "execution_count": null, "outputs": []}, {"metadata": {"id": "sB4lznWP4DX8"}, "cell_type": "markdown", "source": "openCV intergeration"}, {"metadata": {"id": "_TGsuRWs4URA", "outputId": "cba00d19-b030-4e83-eb53-42eed4fb2494", "colab": {"base_uri": "https://localhost:8080/"}}, "cell_type": "code", "source": "account_sid = 'ACe316932976f5aff487f6cdcab9a13579'\nauth_token= '2388b1f10e88371fd6ebeabc00fd3ebf'\nclient = Client (account_sid, auth_token)\nmessage = client.messages\\\n.create(\n    body='Forest Fire is detected, stay alert',\n    from_= '+12183043886',\n    to='+916374835017')\nprint(message.sid)", "execution_count": null, "outputs": []}], "metadata": {"colab": {"provenance": [], "collapsed_sections": []}, "kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "accelerator": "GPU", "gpuClass": "standard"}, "nbformat": 4, "nbformat_minor": 1}